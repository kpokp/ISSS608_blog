---
title: "Individual Assignment Part 2: R Packages, Data and Analysis"
description: |
  Vast Challenge 2021 - The Kronos Incident - Mini Challenge 2
author:
  - name: Kelly Koh
    url: https://www.linkedin.com/in/kellykkw/
    affiliation: School of Computing and Information Systems, Singapore Management University
    affiliation_url: https://scis.smu.edu.sg/
date: 06-10-2021
output:
  distill::distill_article:
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: false
    code_folding: hide
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.retina = 3,
                      fig.width = 10,
                      echo = TRUE,
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

[Part 1: Background and Methodology](https://kellykkw.netlify.app/posts/2021-07-25-individual-assignment-part-1/) 

[Part 2: R Packages, Data and Analysis](https://kellykkw.netlify.app/posts/2021-07-25-individual-assignment-part-2/) 

[Part 3: Insights and Conclusion](https://kellykkw.netlify.app/posts/2021-07-25-individual-assignment-part-3/) 


## 4. R Packages & Data

### 4.1 R Packages

The following R packages are used:

- Loading data from csv files: 'readr'
- Cleaning and manipulating data: 'tidyverse', 'DT', 'fuzzyjoin'
- Manipulate time and date variables: 'lubridate', 'clock', 
- Plot heat maps, gantt, parallel coordinates and scatter plot graphs: 'ggplot2', 'ggforce', 'scales'
- Plot interactive network graph: 'visNetwork',
- Add interactivity to ggplot charts: 'plotly', 'crosstalk',
- Load maps & manipulate geo-spatial data: 'jpeg', 'grid', 'geohashTools', 'sf', 'tmap', 'raster', 'rgdal', 'mapview'

```{r download packages}
# The following R packages are used for respective parts of the workflow:
packages = c( # Loading data from csv files
               'readr',
              # Cleaning and manipulating data 
              'tidyverse', 'DT', 'fuzzyjoin',
              # Manipulate time and date variables
              'lubridate', 'clock', 
              # Plot heat maps, gantt, parallel coordinates and scatter plot graphs
              'ggplot2', 'igraph', 'gghighlight', 'scales', 'ggbreak', 'ggforce','gridExtra',
              # Plot interactive network graph
              'visNetwork',
              # Add interactivity to ggplot charts
              'plotly', 'gganimate', 'quantmod', 'crosstalk',
              # Load maps & manipulate geo-spatial data
              'jpeg', 'grid', 'geohashTools', 'sf', 'tmap', 'patchwork', 'raster', 'rgdal', 'mapview')

for (p in packages) {
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}

```

### 4.2 Datasets

#### 4.2.1 Credit Card Data 
- Contains transaction of each credit card with timestamp, price and location
- 55 unique credit card numbers
- 1,490 credit card transactions

```{r cc data}
cc <- read_csv("data/cc_data.csv",
               col_types = cols(timestamp = col_datetime(format = "%m/%d/%Y %H:%M"), 
                                location = col_character(), 
                                price = col_double(), 
                                last4ccnum = col_double()))

cc <- cc %>% arrange(last4ccnum,timestamp) %>%
  mutate(last4ccnum = as.factor(last4ccnum))

glimpse(cc)
```

#### 4.2.2 Loyalty Card Data 
- Contains transaction on loyalty card with date, price and location
- 54 unique loyalty card numbers
- 1,392 loyalty card transactions

```{r loyalty data}
loyalty <- read_csv("data/loyalty_data.csv",
               col_types = cols(timestamp = col_date(format = "%m/%d/%Y"), 
                                location = col_character(), 
                                price = col_double(), 
                                loyaltynum = col_character()))

loyalty <- loyalty %>% arrange(loyaltynum,timestamp) %>%
  mutate(loyaltynum = as.factor(loyaltynum))

glimpse(loyalty)
```

#### 4.2.3 GPS Data 
- Contains timestamped latitude and longitude of each employee vehicle (ID) when in movement, including trucks which `id` is coded in '10X'
- 40 unique Car IDs (1 to 35, 101, 104 to 107)
- 685,169 records

```{r gps data}
gps <- read_csv("data/gps.csv",
               col_types = cols(Timestamp = col_datetime(format = "%m/%d/%Y  %H:%M:%S"), 
                                id = col_double(), 
                                lat = col_double(), 
                                long = col_double()))

gps <- gps %>% arrange(id, Timestamp) %>%
  mutate(id = as.factor(id))

glimpse(gps)
```

#### 4.2.4 Car Assignment Data 
- Contains full names of employees, department, job title and ID of cars assigned 
- 44 known employees
- 35 cars are given IDs and associated with employees
- 9 trucks drivers are not assigned with particular vehicle ID

```{r car assignment data}
cars <- read_csv("data/car-assignments.csv",
               col_types = cols(LastName = col_character(), 
                                FirstName = col_character(),
                                CarID = col_double(), 
                                CurrentEmploymentType = col_character(),
                                CurrentEmploymentTitle = col_character()))

cars <- cars %>% arrange(CarID) %>%
  mutate(CarID = as.factor(CarID))

glimpse(cars)
```

Beyond the csv files, a tourist map image of Aliba (see Figure 1) and geospatial datasets are provided.

![Figure 1](./images/MC2-tourist.jpg)


## 5. Data Transformation And Analysis

### 5.1 Credit and Loyalty Card Transactions

#### 5.1.1 Correct unrecognized character in location name

Replace the unrecognized characters in Katerina's Cafe location name in credit card & loyalty data using `grep`.

```{r POI names}
# Match names of locations in credit card and loyalty card transactions to check spelling
cc_loc <- cc %>% distinct(location) %>% arrange(location) 

loyalty_loc <- loyalty %>% distinct(location) %>% arrange(location) 

location <- full_join(cc_loc, loyalty_loc, by = "location") %>% 
            arrange(location)

# Replace the unrecognized characters in Katerina's Cafe location in cc & loyalty data
cc[grep("Katerina", cc$location),2] <- "Katerina's Cafe"
loyalty[grep("Katerina", loyalty$location),2] <- "Katerina's Cafe"
```


#### 5.1.2 Join credit card transactions to loyalty transactions - round 1

Credit card transactions are joined with loyalty card transactions using date, location and spend amount as loyalty card transactions do not have time. 
Any credit card and loyalty card match that only has 1 transaction will be removed to avoid spurious match. 

From the 1,081 matched transactions, there are 56 unique pairs of credit cards and loyalty cards, which points to multiple relationship between credit card and loyalty cards. As it is hard to visualize the interconnection between credit cards and loyalty cards in tabular form, a network graph will be used to visualize the relationship.

```{r match round 1}
# Create new date field for credit card data
cc <- cc %>% 
  mutate(datestamp = as.Date(timestamp))

# Join datasets on exact date, location and price (round 1)
# 1,807 records with spurious matches and non-matches
transact <- cc %>% 
  full_join(loyalty, by = c("datestamp" = "timestamp", "location", "price"))

# Find the unique pairs of credit card and loyalty card 
# 56 pairs of credit card and loyalty card pairs
pairs <- transact %>% 
  group_by(last4ccnum, loyaltynum) %>%
  count() %>%
  # Remove 6 spurious matches
  filter(n>1) %>%
  drop_na() %>%
  arrange(last4ccnum,loyaltynum) %>%
  ungroup()

# 1,081 matched transactions 
transact_match <- transact %>% 
  drop_na() %>%
  left_join(pairs, by = c("last4ccnum","loyaltynum")) %>% 
  drop_na()%>%
  dplyr::select(-n) 

glimpse(transact_match)
```

 
#### 5.1.2 Visualize credit card and loyalty cards relationship using network graph

From the network graph, we observe unexpected relationships between credit card 1286 and loyalty card L3288 and loyalty card L6267 is tied to two credit cards 6691 and 6899. 

```{r prep network graph}
# Prepare cc & loyalty matching data for network graph format
last4ccnum <- transact_match %>%
  distinct(last4ccnum) %>%
  rename(label = last4ccnum) %>%
  mutate(group = 'cc')

loyaltynum <- transact_match %>%
  distinct(loyaltynum) %>%
  rename(label = loyaltynum) %>%
  mutate(group = 'loyalty')

nodes <- full_join(loyaltynum, last4ccnum, by = c("label","group"))

nodes <- nodes %>% rowid_to_column("id") 

per_route <- transact_match %>%  
  group_by(loyaltynum, last4ccnum) %>%
  summarise(weight = n()) %>% 
  ungroup()

edges <- per_route %>% 
  left_join(nodes, by = c("last4ccnum" = "label")) %>% 
  rename(from = id)

edges <- edges %>% 
  left_join(nodes, by = c("loyaltynum" = "label")) %>% 
  rename(to = id)

edges <- dplyr::select(edges, from, to, weight) %>% 
  filter(weight > 1) %>% 
  mutate(width = weight/5 + 1)

# Plot network graph to show cc and loyalty cards relationship
netwkgraph <- visNetwork(nodes, edges, width = "100%", 
                         main = list(text = "Relationship Between Credit Card and Loyalty Cards",
 style = "font-family:arial;font-size:20px;")) %>% 
  visOptions(highlightNearest = TRUE,
             nodesIdSelection = list(enabled = TRUE,selected = "1")) %>% 
  visGroups(groupname = "cc", color = "lightblue") %>%    
  visGroups(groupname = "loyalty", color = "orange") %>% 
  visLegend(width = 0.1, position = "right", main = list(text = "Card Types",
 style = "font-family:arial;font-size:15px;"))
netwkgraph
```


#### 5.1.3 Join unmatched credit card transactions to loyalty transactions - round 2

409 loyalty card transactions and 311 credit card transactions were unpaired based on exact date, spend and location. Based on the pairs of credit card and loyalty numbers, we match the remaining unmatched transactions based on date, location and a price range, specifically with loyalty price lower than credit card price. 

Results below show that 219 transactions have loyalty card price lower than credit card prices. The lower amount registered on the loyalty card usually ranges from $20-80, in increments of $20s. There is no obvious bias to any location or cards. This suggests that there might be a systemic program or error that led to this outcome e.g. cashback program.

```{r match round 2 - cashback}
# Create config table based on primary matched pairs of loyalty and credit card numbers detected from network graph 
config <- pairs %>%
  filter(!(last4ccnum %in% c('1286') & loyaltynum %in% c('L3288'))) 

# 1,066 transactions with exact match on date, loyalty number, price and location
exact_match <-  cc %>% 
                left_join(config, by = "last4ccnum") %>% 
                inner_join(loyalty, by = c("datestamp" = "timestamp",
                                           "loyaltynum",
                                           "location","price"))

# 409 cc transactions exclude matches from exact price match
cc_unmatched <- cc %>%
  anti_join(transact_match, by = c("datestamp","last4ccnum","location","price")) 

# 311 loyalty transactions exclude matches from exact price match
loyalty_unmatched <- loyalty %>%
  anti_join(transact_match, by = c("timestamp" = "datestamp","loyaltynum","location","price")) 

# Fuzzy match with loyalty price to be lower or equal to cc price returns 496 entries (round 2)
transact_match_2 <- cc_unmatched %>%
  left_join(config, by = "last4ccnum") %>%
  fuzzy_full_join(loyalty_unmatched, 
                  by = c("loyaltynum", "location",
                           "datestamp"="timestamp","price"="price"),
                  match_fun=list(`==`, `==`, `==`, `>=`)) 

# 219 transactions match with price range with price difference in increments of $20.
transact_match_2 <- transact_match_2 %>%
  drop_na() %>%
  mutate(price_diff = price.x - price.y) %>%
  filter(round(price_diff,0) %in% c(20,40,60,80)) 

# 219 transactions match with price range with price difference in increments of $20.
cashback <- ggplot(transact_match_2, 
            aes(x = price_diff, fill = location.x, 
                text = paste('Price Difference: $', price_diff,
                         '<br>Location: ', location.x,
                         '<br>Count: ', n))) + 
  geom_histogram(boundary = 1, position = "stack") +
  labs(title = "Distribution of Cashback by Locations",
                   x = "Cashback Amount ($)", y = "Count", fill = "Locations") +
  theme_minimal() +
  theme(text = element_text(size=7))
  
ggplotly(cashback, tooltip = c("text"))  
```


#### 5.1.4 Join unmatched credit card transactions to loyalty transactions - round 3

The remaining unmatched transactions are matched based on location and price (and not date) to check for any delayed postings of credit card transactions. Results below show that 7 Kronos Mart credit card transactions were posted 1 day later than its associated loyalty card transactions.

```{r match round 3}
# 190 cc transactions exclude matches from match round 2 (cashback)
cc_unmatched_2 <- cc_unmatched %>%
  anti_join(transact_match_2, by = c("datestamp", 
                                  "location" = "location.x",
                                  "price" = "price.x",
                                  "last4ccnum")) 

# 92 loyalty transactions exclude matches from match round 2 (cashback)
loyalty_unmatched_2 <- loyalty_unmatched %>%
  anti_join(transact_match_2, by = c("timestamp" = "timestamp.y", 
                                     "loyaltynum" = "loyaltynum.y",
                                     "location" = "location.y",
                                     "price" = "price.y")) 

# Match remaining credit card and loyalty card transactions on location and price (round 3)
transact_match_3 <- full_join(cc_unmatched_2, loyalty_unmatched_2, by = c("location","price"))

# 7 Kronos Mart posts credit card transactions posted 1 day later than loyalty card date
transact_match_3 <- transact_match_3 %>% 
  drop_na() %>%
  mutate(diff_date = datestamp - timestamp.y)
        
# Plot scatterplot of Kronos Mart delayed postings
kronos_delay <- ggplot(transact_match_3 %>%
  mutate(CreditCard = as_date(timestamp.x)) %>%
  dplyr::select(price, location, CreditCard, timestamp.y) %>% 
  rename(LoyaltyCard = timestamp.y) %>%
  pivot_longer(!c(location,price), names_to = "type", values_to = "date"), 
                       aes(x=date, y = price, color = type, label = price)) +
  geom_point() +
  geom_text(check_overlap = TRUE, size = 2, nudge_x = 0.5) +
  scale_x_date(date_label = "%a \n%d %b") +  
  theme_minimal() +
  theme(text = element_text(size=7))+
  labs(title = "Daily Transactions of Kronos Mart by Card Type",
                   x = "Date", y = "Price ($)", color = "Card Type")

ggplotly(kronos_delay)
```


#### 5.1.5 Join unmatched credit card transactions to loyalty transactions - round 4

The 4th attempt to match the remaining unmatched transactions based on location and price range, whereby loyalty card price will be greater than credit card price, did not return many matches or a pattern. We will disregard the matches and treat the remainder 183 credit card and 85 loyalty card transactions as situations whereby employees used one of the two cards.

```{r match round 4}
# 183 cc transactions exclude matches from match round 3 (delayed posting)
cc_unmatched_3 <- cc_unmatched_2 %>%
  anti_join(transact_match_3, by = c("datestamp", 
                                  "location",
                                  "price",
                                  "last4ccnum")) 

# 85 loyalty transactions exclude matches from match round 3 (delayed posting)
loyalty_unmatched_3 <- loyalty_unmatched_2 %>%
  anti_join(transact_match_3, by = c("timestamp" = "timestamp.y", 
                                     "loyaltynum" = "loyaltynum",
                                     "location",
                                     "price")) 

# Match with loyalty price to be greater or equal to cc price (round 4)
transact_match_4 <- left_join(cc_unmatched_3,config, by = "last4ccnum") %>%
  fuzzy_full_join(loyalty_unmatched_3, by = c("location",
                                              "price",
                                              "datestamp"="timestamp",
                                              "loyaltynum"),
                  match_fun=list(`==`, 
                              `<=`, 
                              `==`,
                              `==`)) %>%
  drop_na()

DT::datatable(transact_match_4, filter = 'top', width = '100%', options = list(scrollX = TRUE))

```


#### 5.1.6 Final list of transaction records

The final list of spend transactions yielded 1,575 records, which will be explored for patterns and anomalies.

```{r trans final}

transact_match_clean <- transact_match %>%
  mutate(datestamp_loyalty = datestamp, price_diff = NA, diff_date = NA)

transact_match_2_clean <- transact_match_2 %>%
  dplyr::select(timestamp.x,location.x,price.x,last4ccnum,datestamp,loyaltynum.x,timestamp.y, price_diff) %>%
  rename(timestamp = timestamp.x,
         location = location.x,
         price = price.x,
         loyaltynum = loyaltynum.x,
         datestamp_loyalty = timestamp.y) %>%
  mutate(diff_date = NA)

transact_match_3_clean <- transact_match_3 %>%
  dplyr::select(timestamp.x,location,price,last4ccnum,datestamp,loyaltynum,timestamp.y,diff_date) %>%
  rename(timestamp = timestamp.x, datestamp_loyalty = timestamp.y) %>%
  mutate(price_diff = NA)

loyalty_unmatched_3_clean <- loyalty_unmatched_3 %>%
  rename(datestamp = timestamp) %>%
  mutate(datestamp_loyalty = datestamp)

# Final set of 1,575 credit card and loyalty card transactions
trans_final <- transact_match_clean %>%
  bind_rows(transact_match_2_clean) %>%
  bind_rows(transact_match_3_clean) %>% 
  bind_rows(loyalty_unmatched_3_clean) %>% 
  bind_rows(cc_unmatched_3)

DT::datatable(trans_final, filter = 'top', width = '100%', options = list(scrollX = TRUE))
```


#### 5.1.7 Understand hourly spend patterns

From the heatmap below, we observed that some locations only have credit card transactions posted in 1 hour within the day e.g. 

- Bean There Done That and Brewed Awakenings, Jack's Magical Beans, Coffee Shack at 12PM
- Daily Dealz at 6AM. 

Another anomaly that we will investigate is the posting from Kronos Mart at 3AM.

```{r hourly trans pattern}
# Summarize credit card data by hour
cc_hour <- trans_final %>% 
  drop_na(timestamp) %>%
  mutate(hour_cc = as.numeric(get_hour(timestamp))) %>% 
  group_by(location,hour_cc) %>% 
  count() %>%
  rename("transactions" = n) %>%
  ungroup() %>%
  complete(location, hour_cc = full_seq(hour_cc, period = 1)) %>%
  mutate(hour_cc = as.character.numeric_version(hour_cc)) 

# Plot cc hourly data as heatmap using geom_tile()
heatmap_cc <- ggplot(cc_hour, aes(x= hour_cc, y = location, fill = transactions, 
                                  text = paste('No. of Transactions:', transactions,
                                              '<br>Transaction Hour: ', hour_cc,
                                              '<br>Location: ', location))) +
  theme_minimal() +
  theme(text = element_text(size=7))+
  geom_tile(colour="white") +
  labs(x = "Hour", y = "Location") +
  scale_fill_gradient(low = "#E0E1E4", high = "#000000") +
  scale_y_discrete(limits = rev) +
  labs(title = "Hourly Credit Card Transactions",
      x = "Hour", fill = "Transactions") 

# Make heatmap interactive with plotly for exploration
ggplotly(heatmap_cc, tooltip = c("text"))
```


#### 5.1.8 Understand daily spend patterns

From the heatmap below, we see that the top 3 popular locations belong to the Food categories, such as Katerina's Cafe, Brew've Been Served and Hippokampos. Katerina's Cafe peaks on Saturday, Hippokampus is busier on weekdays than weekends and Brew've been Served is closed on weekends.

```{r daily trans patterns}
# Summarize spend data by day
trans_day <- trans_final %>% 
  mutate(date_min = pmin(datestamp, datestamp_loyalty, na.rm=TRUE)) %>%
  group_by(location,date_min) %>% 
  count() %>%
  rename("transactions" = n) %>%
  ungroup() 

break_vec <- trans_day$date_min %>% c(seq(from = min(trans_day$date_min), to = max(trans_day$date_min),by = "day"))

# Plot data as heatmap using geom_tile()
heatmap_spend <- ggplot(trans_day, aes(x= date_min, y = location, fill = transactions, 
                                  text = paste('No. of Transactions:', transactions,
                                              '<br>Transaction Date: ', date_min,
                                              '<br>Location: ', location))) +
  theme_minimal() +
  theme(text = element_text(size=7), axis.text.x=element_text(hjust=1)) +
  geom_tile(colour="white") +
  labs(x = "Date", y = "Location") +
  scale_fill_gradient(low = "#E0E1E4", high = "#000000") +
  scale_y_discrete(limits = rev) +
  scale_x_date(breaks = break_vec, date_label = "%a \n%d %b") +  
  labs(title = "Daily Spend Transactions",
      x = "Date", fill = "Transactions") 

# Make heatmap interactive with plotly for exploration
ggplotly(heatmap_spend, tooltip = c("text"))
```



#### 5.1.9 Understand spend amount

The highest spend on the credit card is $10k on Frydos Autospply n' More that does not have a loyalty card transaction, belonging to credit card 9551. 
9 credit cards (2276, 3506, 4530, 8642, 7792, 9152, 9220, 9614, 9735) register many high spends that are at industrial areas, likely belonging to the 9 truck drivers. 

```{r trans amount, fig.width = 8, fig.height = 5}
spend_cc <-  ggplot(trans_final, aes(x = last4ccnum, y = location, size = price*2, color = location, 
                                     text = paste('Last 4 Credit Card Number:', last4ccnum,
                                                  '<br>Loyalty Card Number:', loyaltynum,
                                              '<br>Price: $', price,
                                              '<br>Date: $', datestamp,
                                              '<br>Location: ', location))) +
  geom_point(alpha = 0.7) + 
  theme_minimal() + 
  theme(text = element_text(size=7), axis.text.x=element_text(angle=45, hjust=1)) +
  scale_y_discrete(limits = rev) +
  labs(title = "Spending at Each Location by Credit Card Number",
      x = "Credit Card Number", y = "Location", color = "Location", size = "Price") 

ggplotly(spend_cc, tooltip = c("text"))
```



#### 5.1.10 Understand Credit Card Spend Frequency

From the chart below, we spot anomalies from the frequency of the spends worth investigating:
- Credit card 9551 saw a peak spend of more than $10k with 5 transactions on 13 Jan and registering no spend for 2 days thereafter
- Early ends - Credit card 5921's last spend was on 19 Jan
- Late starts - Credit card 3547 started having spend on 12 Jan and 5010 started on 17 Jan
- Sporadic records with high spends - Credit cards 2276, 3506, 4530, 7792, 8642 9152, 9220, 9614 

```{r daily spend - spend frequency, fig.height=6}
ly_count <- trans_final %>%
  group_by(datestamp, last4ccnum) %>%
  summarise(n = n(), total_price = sum(price)) %>% 
  drop_na() %>% ungroup()

ly_count_p <- ggplot(ly_count, aes(x = datestamp, y = n, fill = total_price, 
                                   text = paste('Total Spend $', total_price,
                                              '<br>Frequency:', n,
                                              '<br>Date:', datestamp))) + 
  geom_bar(stat='identity') +
  theme_minimal() +
  theme(axis.title.x = element_blank()) +
  theme(text = element_text(size=7), axis.text.x=element_text(angle=45, hjust=1)) +
  facet_wrap(~last4ccnum) +
  theme(panel.spacing = unit(1, "lines")) +
  labs(title = "Daily Transaction Frequency By Credit Card Number",
      fill = "Total Spend ($)") 

ggplotly(ly_count_p, tooltip = c("text"))
```

### 5.2 GPS Logs and Map Layers


#### 5.2.1 Set up map layers using the tourist map provided

We plot the raster layer using tmap to merge the rgb bands and use sf to import the vector GIS files into ESRI shapefile format.

```{r map layers}
# Import MC2-tourist.tif created using QGIS
ap <- raster("data/Geospatial/MC2-tourist.tif")

# Plotting raster layer using tmap to merge rgb bands
tm_shape(ap) +
tm_rgb(ap, r=1,g=2,b=3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255)

# Use sf to import Vector GIS data files in ESRI shapefile format
abila_st <- st_read(dsn = "data/Geospatial",
                    layer = "Abila")

```

#### 5.2.2 Create movement path from GPS logs 

We then create movement path by converting the aspatial data into a data frame and group the paths by id.

```{r gps prep}
# Converting aspatial data into simple feature data frame using st_as_sf
gps_sf <- st_as_sf(gps,
                   coords = c("long","lat"),
                            # EPSG 4326 stands for wgs84 geo. coord sys
                            crs = 4326)

# Group paths by ID and cast as linestring
gps_path <- gps_sf %>%
            group_by(id) %>%
            # Due to peculiar nature of group by, we need to do an action such as summarize
            summarize(m = mean(Timestamp),
                      do_union = FALSE) %>%
            st_cast("LINESTRING") %>%
            ungroup()
# Have to slice the paths by days, or time period to derive meaningful paths
```


#### 5.2.3 Visualize gps paths by Car ID to detect gps anomalies

Results from the maps show that Car ID 28 and 9 have GPS data issues:

- Car ID 28's GPS coordinates are systematically misaligned. Correction can be done by systematically shifting all GPS coordinates using GASTech building as the anchoring position and averaging out the coordinates
- Car ID 9's GPS records are spotty, journeys did not end and start in the same place. Correction can be done by extrapolating journeys. 

```{r plot gps}
# Plot gps paths by car IDs
tmap_mode("view")
tm_shape(ap) +
  tm_rgb(ap, r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
tm_shape(gps_path) +
  tm_lines() +
tm_facets(by = "id", ncol = 4) 
```


Closer look at GPS of Car 28 and 9:
```{r faulty gps of 28 & 9}
# Zoom in on car 28 & 9
gps_path_selected <- gps_path %>% filter(id %in% c("28","9"))

tmap_mode("view")

tm_shape(ap) +
  tm_rgb(ap, r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
tm_shape(gps_path_selected) +
  tm_lines() +
tm_facets(by = "id", ncol = 2)
```



#### 5.2.4 Resolve data issues in Car 28 GPS log by taking the average coordinates over a wider time interval

Car ID 28's jittery GPS logs resolved by taking the mean coordinates over a 20 second interval. 

```{r fix gps 28}
# Change GPS timestamp to POSIX format
gps$Timestamp <- as.POSIXct(gps$Timestamp, format = "%m/%d/%Y  %H:%M:%S")

# Group timestamp in intervals of 20 seconds and select the mean coordinates to smoothen out the path
gps_28 <- gps %>%
  filter(id == "28") %>%
  mutate(Timestamp = round_date(Timestamp, "20 sec")) %>%
  mutate(lat = round(lat - 00.004,3) ) %>% 
  mutate(long = round(long + 00.004,3) ) %>%
  group_by(Timestamp) %>%
  summarise(lat = mean(lat, na.rm = FALSE), long = mean(long, na.rm = FALSE)) %>% 
  mutate(id = "28") %>%
  ungroup() 

# Visualize car 28 GPS movement
gps_sf_28 <- st_as_sf(gps_28,
                   coords = c("long","lat"),
                            # EPSG 4326 which stands for wgs84 geo. coord sys
                            crs = 4326)

gps_path_28 <- gps_sf_28 %>%
  group_by(id) %>%
  # Due to peculiar nature of group by, we need to do an action such as summarize
  summarize(m = mean(Timestamp),
            do_union = FALSE) %>%
  st_cast("LINESTRING") %>%
  ungroup()

tmap_mode("view")

tm_shape(ap) +
  tm_rgb(ap, r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
tm_shape(gps_path_28) +
  tm_lines()

```

#### 5.2.5 Resolve data issues in Car 9 GPS log

Car ID 9 missing GPS records seems to occur randomly. Unfortunately, we are unable to extrapolate the missing GPS records with safe assumptions. We would take note to register events of Car ID 9 by taking the location when the car stopped or start, whichever that makes more sense (i.e. closer to a meaningful location). 

```{r fix gps 9}
# Understand car ID 9's GPS pattern
gps_9 <- gps %>% 
  mutate(datestamp = as_date(Timestamp)) %>%
  mutate(time = as.POSIXct(Timestamp,format = "%H:%M:%S")) %>%
  filter(id == "9", datestamp == "2014-01-07") 

# Plot GPS pattern in scatterplot chart
gps_9_line <- gps_9 %>%
  ggplot(aes(x = time, y = lat)) +
  geom_point() +
  geom_line(color = "red") +
  facet_grid(row = vars(datestamp), scales = "free") +
  labs(title = "Latitude Coordinates of Car ID 9",
                   x = "Time", y = "Latitude")  

ggplotly(gps_9_line)  
```

#### 5.2.6 Detect and process events from GPS log

Stops between GPS logs provides clues to where the person was heading to. This study will define all stops between GPS log records that spans above 5 minutes as events to be investigated. Each event will have a time span, a location, and a person tied to it. As a rule of thumb, homes of employee will be first identified as locations with pauses between GPS logs exceeding 5 hours for further investigation. 

```{r event prep}
# Replace gps records of Car ID 28
gps_28 <- gps_28 %>%
  dplyr::select(Timestamp, id, lat, long)

gps_clean <- gps %>%
  filter(!id == "28") %>%
  rbind(gps_28) 

# Make car assignment table neat
cars_neat <- cars %>% 
  unite("name", FirstName, LastName, sep = " ") %>%
  rename(department = CurrentEmploymentType , title = CurrentEmploymentTitle)

# Merge car assignments to gps data & sort table by id & timestamp
gps_name <- gps_clean %>%
  left_join(cars_neat, by = c("id" = "CarID")) %>%
  arrange(id, Timestamp) %>%
  mutate(Timestamp = as.POSIXct(Timestamp, format = "%m/%d/%Y  %H:%M:%S"))

# Find difference between timestamp and id
gps_name_temp <- dplyr::select(gps_name,Timestamp)

time_diff <- tail(gps_name_temp,-1) - head(gps_name_temp,-1)

# Join & Tag Start and Stop for Intervals > 5 min
gps_name_diff <- bind_cols(time_diff$Timestamp,tail(gps_name,-1)) %>%
  rename(diff=...1) %>%
  group_by(id) %>%
  
  # If interval btw timestamps is more than 5 mins, tag as an event
  mutate(event_stop = ifelse(diff/60 > 5,'stop',
                          ifelse(diff/60 < 0,'stop',NA))) %>%
  mutate(event_start = lead(event_stop)) %>% 
  
  # If interval between timestamps is more than 5 hours, tag as home to help identify home locations later
  mutate(home = ifelse(diff/60/60 > 5,'home',NA)) %>%
  mutate(diff = seconds_to_period(diff)) %>%
  mutate(event_start = ifelse(event_start == 'stop','start',NA)) %>%
  
  # Encode lat long into geohash level 7    
  mutate(geohash = gh_encode(latitude = lat, 
                               longitude = long, 
                               precision = 7L)) %>%
  ungroup() 
```


#### 5.2.7 Identify events of Car ID 9 and 28

There is a need to consciously merge the start and stop locations of Car ID 9 as there are places of the interest that are registered by starts (e.g. Bean There Done That) and places registered by stops (e.g. U Pump). We will do the event patching if events identified cannot be matched to a location. 

```{r car 9 events}
# Inspect events of Car ID 9
events_9 <- gps_name_diff %>% 
          filter(id == "9", event_stop == "stop" | event_start == "start") %>%
          unite(event, c("event_start", "event_stop")) %>%
          dplyr::select(Timestamp, lat, long, event)

# view the locations over the jpeg map
map <- ggplot(events_9, aes(long, lat)) + 
    
    theme(panel.border = element_blank(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.line = element_line(colour = "grey")) +

  # Add points
    geom_point(aes(color=event), size = 3, alpha = 0.8) +
  
  # Add label
    labs(title = "Start and Stop Coordinates of Car ID 9 Events",
                   x = "Longitude", y = "Latitude", color = "Type of Events")

# Use ggplotly to make it interactive so we can pick the right geohash visually
pp <- ggplotly(map)
layout(pp, images = list(
  list(
    source = "https://raw.githubusercontent.com/kpokp/ISSS608_blog/main/_posts/2021-06-10-individual-assignment/images/MC2-tourist.jpg",
    opacity = 0.3,
    layer = "below",
    xref = "x",
    yref = "y",
    sizing="stretch",
    x= 24.8244,
    y= 36.0952,
    sizex= 0.0852,
    sizey= 0.05
  )
))

```

```{r car 28 events}
# Inspect events of Car ID 9
events_28 <- gps_name_diff %>% 
          filter(id == "28", event_stop == "stop" | event_start == "start") %>%
          unite(event, c("event_start", "event_stop")) %>%
          dplyr::select(Timestamp, lat, long, event)

# view the locations over the jpeg map
map <- ggplot(events_28, aes(long, lat)) + 
    
    theme(panel.border = element_blank(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.line = element_line(colour = "grey")) +

  # Add points
    geom_point(aes(color=event), size = 3, alpha = 0.8) +
  
  # Add label
    labs(title = "Start and Stop Coordinates of Car ID 28 Events",
                   x = "Longitude", y = "Latitude", color = "Type of Events")

# Use ggplotly to make it interactive so we can pick the right geohash visually
pp <- ggplotly(map)
layout(pp, images = list(
  list(
    source = "https://raw.githubusercontent.com/kpokp/ISSS608_blog/main/_posts/2021-06-10-individual-assignment/images/MC2-tourist.jpg",
    opacity = 0.3,
    layer = "below",
    xref = "x",
    yref = "y",
    sizing="stretch",
    x= 24.8244,
    y= 36.0952,
    sizex= 0.0852,
    sizey= 0.05
  )
))

```

#### 5.2.8 Capture all GPS events 

3,067 events with locations that would be later identified as home, places of interest, or unknown/suspicious locations.

```{r events}
# 3,067 events that span more than 5 minutes
events <- gps_name_diff %>%
  filter(event_stop == "stop") %>%
  mutate(event_start_time = Timestamp - diff) %>%
  rename(event_stop_time = Timestamp) %>% 
  mutate(event_date = as_date(event_start_time)) %>% 
  dplyr::select(event_stop, home,event_date, event_start_time, event_stop_time,
                        diff, lat, long, geohash, id, name, department, title) %>%
  filter(diff > 0)

glimpse(events)
```

#### 5.2.9 Identify home locations of employees

The interactive map shows that some of the employees stay together e.g. employees with Car ID 30, 22 and 23. 

Furthermore, due to GPS issues, employee with Car ID 28 has home locations spread around a concentrated area, while employee with Car ID 9 spreads out over a wider area. 

We also picked up GASTech as a location especially for truck drivers, who park their vehicles at the company at the end of their work day.

```{r home events}
# Identify homes or place of accommodation of employees - 500 events
home <- events %>% 
  filter(home == "home") 

home_freq <- home %>%
  dplyr::select(id, lat, long, geohash) %>%
  mutate(lat = round(lat,3), long = round(long,3)) %>%              
  group_by(id, lat, long, geohash) %>%
  summarise(n = n()) %>%
  ungroup()

# view the home locations over the jpeg map
map <- ggplot(home_freq, aes(long, lat, text = paste("geohash:", geohash))) + 
    
    theme(panel.border = element_blank(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.line = element_line(colour = "grey")) +

  # Add points
    geom_point(aes(color=id, size = n), alpha = 0.8) +
  
  # Add label
    labs(title = "Likely Home Locations by Car IDs",
                   x = "Longitude", y = "Latitude", color = "Car ID", size = "Size of Bubbles - Frequency")

# Use ggplotly to make it interactive so we can pick the right geohash visually
pp <- ggplotly(map)
layout(pp, images = list(
  list(
    source = "https://raw.githubusercontent.com/kpokp/ISSS608_blog/main/_posts/2021-06-10-individual-assignment/images/MC2-tourist.jpg",
    opacity = 0.3,
    layer = "below",
    xref = "x",
    yref = "y",
    sizing="stretch",
    x= 24.8244,
    y= 36.0952,
    sizex= 0.0852,
    sizey= 0.05
  )
))

```


#### 5.2.10 Identify likely geohash of employees' homes locations 

```{r home config}
# Home location config table
location_labels_home <- home_freq %>% 
  group_by(id) %>%
  arrange(desc(n)) %>%
  slice_head() %>% 
  ungroup() %>%
  dplyr::select(geohash, id) %>%
  group_by(geohash) %>% 
  mutate(location = paste0(id, collapse = "/")) %>%
  arrange(geohash) %>%
  slice_head() %>% 
  mutate(label = "Home") %>%
  mutate(location = paste(label,location, sep = " ")) %>%
  dplyr::select(!c(id,label)) %>%
  ungroup()
  
location_labels_home <- home %>% 
  left_join(location_labels_home, by = "geohash") %>%
  drop_na() %>% 
  group_by(location) %>%
  arrange(location) %>%
  slice_head() %>%
  ungroup() %>% 
  mutate(category = "Home") %>%
  dplyr::select("lat","long","geohash","location","category") %>%
  mutate(location = ifelse(geohash == "sw3tn4k", "GASTech", 
                                  ifelse(geohash == "sw3tnw2", "Chostus Hotel",location))) %>%
  mutate(category = ifelse(location == "GASTech", "Company", 
                                  ifelse(location == "Chostus Hotel", "Leisure","Home"))) 

# view the POIs over the jpeg map
map <- ggplot(location_labels_home, aes(long, lat, text = paste('Geohash:', geohash,
                         '<br>Latitude: ', lat,
                         '<br>Longitude: ', long,
                         '<br>Location: ', location))) + 
    
    theme(panel.border = element_blank(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.line = element_line(colour = "grey")) +

  # Add points
    geom_point(aes(color=location), alpha = 0.8, size =4) +
  
  # Add label
    labs(title = "Accommodation Locations by Car IDs",
                   x = "Longitude", y = "Latitude", color = "Accommodation")

# Use ggplotly to make it interactive so we can pick the right geohash visually
pp <- ggplotly(map, tooltip = "text")
layout(pp, images = list(
  list(
    source = "https://raw.githubusercontent.com/kpokp/ISSS608_blog/main/_posts/2021-06-10-individual-assignment/images/MC2-tourist.jpg",
    opacity = 0.3,
    layer = "below",
    xref = "x",
    yref = "y",
    sizing="stretch",
    x= 24.8244,
    y= 36.0952,
    sizex= 0.0852,
    sizey= 0.05
  )
))
```

#### 5.2.11 Identify relationships of employees who share homes  

From the parallel coordinate plot, we see that 8 of the 15 employees who stay in shared homes are from the Security department. 2 of the homes - Home 13/15/16/21 and Home 22/23/30 are occupied only by employees of the Security department. Home 13/15/16/21 occupants take up Perimeter and Site Control duties while Home 22/23/30 occupants are from the Badging Office and one of them is a Security Group Manager. The other 2 homes make up of employees from varied departments such as Engineering, Facilities, IT and Security IT. 

```{r relationships between shared homes}
# Prepare datatset for parallel coordinates plot
cars_home <- cars_neat %>%
  filter(CarID %in% c("22","23","30","6","25","29","17","24","33","13","15","16","21","14","18")) %>%
  mutate(location = ifelse(CarID %in% c("22","23","30"),"Home 22/23/30",
                           ifelse(CarID %in% c("6","25","29"),"Home 6/25/29",
                           ifelse(CarID %in% c("14","18"),"Home 14/18",
                           ifelse(CarID %in% c("17","24","33"),"Home 17/24/33",
                           ifelse(CarID %in% c("13","15","16","21"),"Home 13/15/16/21",NA)))))) %>%
  rename(a.CarID = CarID, b.name = name, c.location = location, d.department = department, e.title = title) %>%
  group_by(b.name, a.CarID, d.department, e.title, c.location) %>%
  summarise(freq = n()) %>%
  gather_set_data(1:5) %>%
  ungroup()

# Plot parallel coordinate plot
home_para_cord <- ggplot(cars_home, aes(x, id = id, split = y, value = freq)) +
  geom_parallel_sets(aes(fill = c.location), alpha = 0.3, axis.width = 0.1) +
  geom_parallel_sets_axes(axis.width = 0.1, fill = "white", colour = "lightgrey") +
  geom_parallel_sets_labels(colour ="black",angle = 360,size = 3) +
  theme_minimal() +
  theme(panel.grid.major = element_blank(),
        axis.text.y = element_blank(),
        axis.line = element_blank()) +
 # Add label
  labs(title = "Characteristics of Employees Sharing Homes",
       x = "Characteristics", fill = "Home Locations") 
  #facet_grid(~location)

home_para_cord
  
```




