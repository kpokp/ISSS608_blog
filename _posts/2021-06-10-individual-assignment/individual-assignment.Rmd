---
title: "Individual Assignment (WIP)"
description: |
  Student hard at work. Check back next time. 
draft: TRUE
preview: images/wip.png
author:
  - name: Kelly Koh
    url: https://www.linkedin.com/in/kellykkw/
    affiliation: School of Computing and Information Systems, Singapore Management University
    affiliation_url: https://scis.smu.edu.sg/
date: 06-10-2021
output:
  distill::distill_article:
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: false
---

## Background

### Vast Challenge 2021 - The Kronos Incident
In the roughly twenty years that Tethys-based GAStech has been operating a natural gas production site in the island country of Kronos, it has produced remarkable profits and developed strong relationships with the government of Kronos. However, GAStech has not been as successful in demonstrating environmental stewardship.

In January, 2014, the leaders of GAStech are celebrating their new-found fortune as a result of the initial public offering of their very successful company. In the midst of this celebration, several employees of GAStech go missing. An organization known as the Protectors of Kronos (POK) is suspected in the disappearance, but things may not be what they seem.

### Mini Challenge 2 Background
GAStech provides many of their employees with company cars for their personal and professional use, but unbeknownst to the employees, the cars are equipped with GPS tracking devices. We are given tracking data for the two weeks leading up to the disappearance, as well as credit card transactions and loyalty card usage data. From this data, we would identify anomalies and suspicious behaviors and identify which people use which credit and loyalty cards.

## Methodology and Visualisation 

### Understand the Spend Transactions

### Understand the Car Movement

### Unify View of Transactions and the Car Movement 


## R Packages and Datasets

### The following R packages are used for respective parts of the workflow:
```{r download packages, include = TRUE, warning = FALSE}
packages = c(
              # Loading data from csv files
               'readr',
              # Cleaning and manipulating data 
              'tidyverse', 'DT', 'fuzzyjoin',
              # Manipulate time and date variables
              'lubridate', 'clock',
              # Find anomaly in time-series data
              'timetk',
              # Plot heat maps, path and scatter plot graphs
              'ggplot2', 'igraph',
              # Plot interactive network graph
              'visNetwork',
              # Add interactivity to ggplot charts
              'plotly', 'gganimate',
              # Load maps & manipulate geo-spatial data
              'jpeg', 'grid', 'geohashTools', 'sf', 'tmap', 'patchwork', 'raster', 'rgdal')

for (p in packages) {
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

### There are 4 datasets provided:

- **Credit card data**: transaction of each credit card with time stamp, price and location. 
- 55 unique credit card numbers
- 1490 cc transactions

```{r cc data, warning=FALSE, include=TRUE, paged.print=TRUE}
cc <- read_csv("data/cc_data.csv",
               col_types = cols(timestamp = col_datetime(format = "%m/%d/%Y  %H:%M"), 
                                location = col_character(), 
                                price = col_double(), 
                                last4ccnum = col_factor()))
glimpse(cc)
```

- **Loyalty card data**: transaction on loyalty card with date, price and location. 
- 54 unique loyalty card numbers
- 1392 loyalty card transactions

```{r loyalty data, include = TRUE, warning = FALSE}
loyalty <- read_csv("data/loyalty_data.csv",
               col_types = cols(timestamp = col_date(format = "%m/%d/%Y"), 
                                location = col_character(), 
                                price = col_double(), 
                                loyaltynum = col_factor()))
glimpse(loyalty)
```

- **GPS data**: latitude and longitude of each employee vehicle (ID) when in movement

```{r gps data, include = TRUE, warning = FALSE}
gps <- read_csv("data/gps.csv",
               col_types = cols(Timestamp = col_datetime(format = "%m/%d/%Y  %H:%M:%S"), 
                                id = col_factor(), 
                                lat = col_double(), 
                                long = col_double()))
glimpse(gps)
```

- **Car assignment data**: full name of employee and ID of car assigned 

```{r car assignment data, include = TRUE, warning = FALSE}
cars <- read_csv("data/car-assignments.csv",
               col_types = cols(LastName = col_character(), 
                                FirstName = col_character(),
                                CarID = col_factor(), 
                                CurrentEmploymentType = col_character(),
                                CurrentEmploymentTitle = col_character()))
glimpse(cars)
```

## Data Preparation

### Data Cleaning

Match names of locations in credit card and loyalty card transactions to check spelling

```{r POI names, warning=FALSE, include=TRUE}
cc_loc <- cc %>% distinct(location) %>% arrange(location) 

loyalty_loc <- loyalty %>% distinct(location) %>% arrange(location) 

location <- full_join(cc_loc, loyalty_loc, by = "location") %>% 
            arrange(location)
location
```

Replace the unrecognized characters in Katerina's Cafe location in cc & loyalty data

```{r update POI name, warning=FALSE, include=TRUE}
cc[grep("Katerina", cc$location),2] <- "Katerina's Cafe"
loyalty[grep("Katerina", loyalty$location),2] <- "Katerina's Cafe"
```

Assign categories to add semantics to 34 points-of-interest (POI)

```{r POI category, warning=FALSE, include=TRUE, paged.print=TRUE}
food <- c("Abila Zacharo","Bean There Done That","Brew've Been Served",
          "Brewed Awakenings","Coffee Cameleon","Coffee Shack","Gelatogalore",
          "Guy's Gyros", "Hallowed Grounds","Hippokampos","Jack's Magical Beans", 
          "Kalami Kafenion", "Katerina's Cafe","Ouzeri Elian")
retail <- c("Albert's Fine Clothing","Daily Dealz","General Grocer","Kronos Mart",
            "Roberts and Sons", "Shoppers' Delight")
gas <- c("Frank's Fuel","U-Pump")
leisure <- c("Abila Airport","Ahaggo Museum","Chostus Hotel","Desafio Golf Course")
company <- c("Abila Scrapyard","Carlyle Chemical Inc.","Frydos Autosupply n' More",
             "Kronos Pipe and Irrigation","Maximum Iron and Steel",
             "Nationwide Refinery","Octavio's Office Supplies","Stewart and Sons Fabrication")

cc %>% mutate(category = 
                    ifelse(location %in% food, "Food",
                    ifelse(location %in% retail, "Retail",
                    ifelse(location %in% gas, "Gas",
                    ifelse(location %in% leisure, "Leisure",
                    ifelse(location %in% company, "Company", NA)))))) 

loyalty %>% mutate(category = 
                    ifelse(location %in% food, "Food",
                    ifelse(location %in% retail, "Retail",
                    ifelse(location %in% gas, "Gas",
                    ifelse(location %in% leisure, "Leisure",
                    ifelse(location %in% company, "Company", NA)))))) 
```

Check credit card transactions postings by locations by hour for patterns

```{r cc patterns, warning=FALSE, include=TRUE, paged.print=TRUE}
# Summarize cc data by hour
cc_hour <- cc %>% mutate(hour_cc = as.character.numeric_version(get_hour(timestamp))) %>% 
                  group_by(location,hour_cc) %>% 
                  count() %>%
                  rename("transactions" = n)

# Plot cc hourly data as heatmap
test <- cc_hour %>% filter(location == "Kronos Mart") 
heatmap_cc <- ggplot(cc_hour, aes(x= hour_cc, y = location, fill = transactions)) +
              theme_minimal() +
              geom_tile(colour="white") +
              labs(x = "Hour", y = "Location") +
              scale_fill_gradient(low = "#dfe1eb", high = "#261fb4") +
              labs(title = "Credit Card Spend by Hour",
                   x = "Hour", fill = "Transactions")

ggplotly(heatmap_cc)
```

We observed that some locations only have credit card transactions posted in 1 hour within the day e.g. 

- Bean There Done That and Brewed Awakenings, Jack's Magical Beans, Coffee Shack at 12PM
- Daily Dealz at 6AM. 

Another anomaly that we will investigate is the posting from Kronos Mart at 3AM.



Merge credit card transactions to loyalty transactions

- To merge using date, location and spend amount as loyalty card transaction does not have time
- To remove spurious matches, any match that only has 1 count will be removed

```{r merge cc & loyalty, include = TRUE, warning = FALSE}
# Create new date field for credit card data
cc <- cc %>% 
      mutate(datestamp = as.Date(timestamp))

# Join datasets on date, location and price 
transact <- full_join(cc,loyalty, by = c("datestamp" = "timestamp","location","price")) %>%             view()

transact %>% drop_na() %>% view()
# 1087 paired trans - with possibility of spurious matches

# Find the unique pairs of credit card and loyalty card 
pairs <- transact %>% group_by(last4ccnum, loyaltynum) %>%
             count() %>%
             # Remove 6 spurious matches
             filter(n>1) %>%
             drop_na() %>%
             arrange(last4ccnum,loyaltynum) %>% 
             view()
```

We will look into resolving certain data quality issues to enhance the pairing. 

As it is hard to visualize the interconnection between credit cards and loyalty cards in tabular form, we will use a network graph.  


Prepare cc & loyalty matching data for network graph format

```{r prep network graph, warning=FALSE, include=TRUE, paged.print=TRUE}
transact_match <- transact %>% drop_na()

last4ccnum <- transact_match %>%
  distinct(last4ccnum) %>%
  rename(label = last4ccnum) %>%
  mutate(group = 'cc')

loyaltynum <- transact_match %>%
  distinct(loyaltynum) %>%
  rename(label = loyaltynum) %>%
  mutate(group = 'loyalty')

nodes <- full_join(loyaltynum, last4ccnum, by = c("label","group"))

nodes <- nodes %>% rowid_to_column("id") %>% view()

per_route <- transact_match %>%  
  group_by(loyaltynum, last4ccnum) %>%
  summarise(weight = n()) %>% 
  ungroup()

edges <- per_route %>% 
  left_join(nodes, by = c("last4ccnum" = "label")) %>% 
  rename(from = id)

edges <- edges %>% 
  left_join(nodes, by = c("loyaltynum" = "label")) %>% 
  rename(to = id)

edges <- dplyr::select(edges, from, to, weight) %>% 
  filter(weight > 1) %>% 
  mutate(width = weight/5 + 1) %>% 
  view()

routes_igraph <- graph_from_data_frame(d = edges, vertices = nodes, directed = TRUE)
```

Plot network graph to show cc and loyalty cards relationship

```{r network graph of txn, warning=FALSE, include=TRUE, paged.print=TRUE}
# https://www.jessesadler.com/post/network-analysis-with-r/
# plot(routes_igraph, edge.arrow.size = 0.2, layout = layout_with_graphopt)
visNetwork(nodes, edges, width = "100%", main = "Credit Card and Loyalty Card Relationships") %>% 
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>% 
  visGroups(groupname = "cc", color = "lightblue") %>%    
  visGroups(groupname = "loyalty", color = "orange") %>% 
  visLegend(width = 0.1, position = "right", main = "Group")
```


- We found unexpected relationships: 1286 & L3288, L6267 - 6691 & 6899

Merge unmatched credit card transactions to loyalty transactions

- 326 loyalty card transactions and 424 credit card transactions were unpaired
- Based on the pairs of cc and loyalty numbers, match the remaining unmatched transactions based on date, location and price range

```{r unmatched trans, warning=FALSE, include=TRUE, paged.print=TRUE}
# Create config table based on matched loyalty and credit card numbers 
config <- pairs %>% 
          filter(!(last4ccnum %in% c('1286') & loyaltynum %in% c('L3288'))) %>% 
          dplyr::select(last4ccnum, loyaltynum) %>%
          view()

# 1066 transactions with exact match on date, loyalty number, price and location
exact_match <-  cc %>% 
                left_join(config, by = "last4ccnum") %>% 
                inner_join(loyalty, by = c("datestamp" = "timestamp",
                                           "loyaltynum",
                                           "location","price")) %>%
                view()

# 424 cc transactions exclude matches from exact price match
cc_unmatched <- cc %>% 
                anti_join(exact_match, by = c("datestamp", 
                                              "last4ccnum",
                                              "location","price")) %>%
                view()

# 326 loyalty transactions exclude matches from exact price match
loyalty_unmatched <- loyalty %>%
                     anti_join(exact_match, 
                               by = c("timestamp" = "datestamp",
                                      "loyaltynum","location","price")) %>%
                     view()

# Match with loyalty price to be lower or equal to cc price
loyalty_cashback <- cc_unmatched %>% 
                    left_join(config, by = "last4ccnum") %>%
                    fuzzy_full_join(loyalty_unmatched, 
                    by = c("loyaltynum", "location",
                           "datestamp"="timestamp","price"="price"),
                    match_fun=list(`==`, `==`, `==`, `>=`)) %>%
                    view()

# 219 transactions match with price range with price difference in increments of $20.
loyalty_cashback <- loyalty_cashback %>%
                    drop_na() %>%
                    mutate(price_diff = price.x - price.y) %>% 
                    filter(round(price_diff,0) %in% c(20,40,60,80)) %>% 
                    view()
```

The cashback amount on the loyalty card usually ranges from 20-80, in increments of 20s.


- Based on the pairs of cc and loyalty numbers, match the remaining unmatched transactions based on location and price to check for any delayed postings

```{r unmatched trans 2, warning=FALSE, include=TRUE, paged.print=TRUE}
# 205 cc transactions exclude matches from cashback match
cc_unmatched_2 <- anti_join(cc_unmatched, loyalty_cashback, 
                             by = c("datestamp", 
                                  "location" = "location.x",
                                  "price" = "price.x",
                                  "last4ccnum")) %>%
                view()

# 107 loyalty transactions exclude matches from cashback match
loyalty_unmatched_2 <- anti_join(loyalty_unmatched, loyalty_cashback, 
                                 by = c("timestamp" = "timestamp.y", 
                                        "loyaltynum" = "loyaltynum.y",
                                        "location" = "location.y",
                                        "price" = "price.y")) %>%
                     view()

cc_delay_post <- full_join(cc_unmatched_2, loyalty_unmatched_2, 
                          by = c("location", 
                                 "price")) %>%
                 view()

# 7 Kronos Mart posts credit card transactions posted 1 day late
# 15 transactions between 1286 & L3288
cc_delay_post_2 <- cc_delay_post %>% 
                  drop_na() %>%
                  mutate(diff_date = datestamp - timestamp.y) %>%
                  view()

```


- Based on the pairs of cc and loyalty numbers, match the remaining unmatched transactions based on location and price range

```{r unmatched trans 3, warning=FALSE, include=TRUE, paged.print=TRUE}
# 183 cc transactions exclude matches from delay post
cc_unmatched_3 <- cc_delay_post %>% 
                  filter_all(any_vars(is.na(.))) %>% 
                  drop_na(last4ccnum) %>%
                  dplyr::select(timestamp.x, location, 
                              price, last4ccnum, 
                              datestamp) %>% 
                  view()

# 85 loyalty transactions exclude matches from delay post
loyalty_unmatched_3 <- cc_delay_post %>% 
                      filter_all(any_vars(is.na(.))) %>% 
                      drop_na(loyaltynum) %>%
                      dplyr::select(location, price, 
                                   timestamp.y, loyaltynum) %>%
                      view()

# Match with loyalty price to be greater or equal to cc price
cc_cashback <- left_join(cc_unmatched_3,config, 
                         by = "last4ccnum") %>% 
               fuzzy_full_join(loyalty_unmatched_3, 
               by = c("location",
                      "price",
                      "datestamp"="timestamp.y",
                      "loyaltynum"),
               match_fun=list(`==`, 
                              `==`, 
                              `<=`,
                              `==`)) %>%
               view()


```

```{r final trans, warning=FALSE, include=TRUE, paged.print=TRUE}
loyalty_cashback_final <- loyalty_cashback %>%
                          dplyr::select(timestamp.x,
                                       location.x, price.x, last4ccnum,
                                       datestamp, loyaltynum.x) %>%
                           rename(timestamp = timestamp.x, 
                           location = location.x,
                           price = price.x,
                           loyaltynum = loyaltynum.x)

cc_delay_post_final <- cc_delay_post_2 %>% 
                       dplyr::select(timestamp.x, 
                                    location, price, last4ccnum,
                                    datestamp, loyaltynum) %>%
                       rename(timestamp = timestamp.x)

trans_final <- exact_match %>%
               union_all(loyalty_cashback_final) %>%
               union_all(cc_delay_post_final) %>%
               view()

```

Detect events from GPS log

- To define all stops above 5 minutes in GPS logs as events
- Each event will have a time span, a location, and a person
- Identify home of employee as the location with the location with the longest span

```{r gps prep, include = TRUE, warning = FALSE}

# Merge car assignments to gps data & sort table by id & timestamp
gps_name <- left_join(gps,cars, by = c("id" = "CarID")) %>%
            unite("name", FirstName, LastName, sep = " ") %>%
            arrange(id,Timestamp)

# Changing timestamp in gps to just date
gps_name$Timestamp <- as.POSIXct(gps_name$Timestamp, 
                                 format = "%m/%d/%Y  %H:%M:%S")

# Find difference between timestamp and id
gps_name_temp <- dplyr::select(gps_name,Timestamp)
time_diff <- tail(gps_name_temp,-1) - head(gps_name_temp,-1)

# Join & Tag Start and Stop for Intervals > 5 min
gps_name_diff <- bind_cols(time_diff$Timestamp,tail(gps_name,-1)) %>%
    rename(diff=...1) %>%
    group_by(id) %>%
    # If interval btw timestamps is more than 5 mins, it is an event
    mutate(event_stop = ifelse(diff/60 > 5,'stop',
                          ifelse(diff/60 < 0,'stop',NA))) %>%
    mutate(event_start = lead(event_stop)) %>% 
    mutate(home = ifelse(diff/60/60 > 6,'home',NA)) %>%
    mutate(diff = seconds_to_period(diff)) %>%
    mutate(event_start = ifelse(event_start == 'stop','start',NA)) %>%
    # Encode lat long into geohash    
    mutate(geohash = gh_encode(latitude = lat, 
                               longitude = long, 
                               precision = 7L)) %>%
    ungroup()
```

Find out the lat long of credit card events based on time frame
- If the transaction time is within the time span of an event, it is assigned to that event

```{r event and transactions, include = TRUE, warning = FALSE}
# Select events that are not staying at home by excluding home
events <- gps_name_diff %>% 
          filter(event_stop == "stop") %>%
          filter(is.na(home)) %>%
          mutate(event_start_time = Timestamp - diff) %>%
          rename(event_stop_time = Timestamp) %>% 
          dplyr::select(event_stop, event_start_time, event_stop_time,
                        diff, lat, long, geohash, id, name) %>%
          view()

# Select distinct timestamp with each location from transactions
trans_time <-   trans_final %>% 
                # Exclude locations with credit card posting timing issues  
                filter(!location %in% c("Bean There Done That","Brewed Awakenings","Jack's Magical Beans","Coffee Shack","Kronos Mart")) %>% 
                dplyr::select(location, timestamp) %>% 
                distinct(location, timestamp) 
               
# Fuzzy match of events and transactions by time windows
events_trans <- events %>% 
                fuzzy_left_join(trans_time, 
                by = c("event_start_time" = "timestamp", "event_stop_time" = "timestamp"),
                match_fun = list(`<`,`>`)) %>%
                view()   

# Prepare the matched data for visualization after dropping the matches that are less than 4
POI <- events_trans %>% drop_na() %>%
                 mutate(lat = round(lat,3), long = round(long,3)) %>% 
                 #filter(!geohash %in% c("sw3tn4k","sw3tnee")) %>% 
                 dplyr::select(location, lat, long, geohash) %>% 
                 group_by(location, lat, long, geohash) %>% 
                 summarise(n = n()) %>%
                 ungroup() %>% 
                 arrange(location, desc(n)) %>% 
                 group_by(location) %>%
                 #top_n(n = 5) %>%
                 ungroup() %>% view()

```


### Setup the map layers 
```{r map layers, include = FALSE, warning = FALSE}
# Adding jpeg file into environment
mc2 <- jpeg::readJPEG("images/MC2-tourist.jpg", native = TRUE)

# Adding KML file into environment
abila <- readOGR("data/Geospatial/Abila.kml", "Abila")
```

### Plot the events that coincide with transactions to determine the lat long of POIs
```{r coordinates, include = TRUE, warning = FALSE}
#view the KML file over the jpeg map
map <- ggplot(POI, aes(long, lat, text = paste("geohash:", geohash))) + 
    
    theme(panel.border = element_blank(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.line = element_line(colour = "grey")) +

  # Add points
    geom_point(aes(size = n, color=location, alpha = 0.8))

pp <- ggplotly(map)
layout(pp, images = list(
  list(
    source = "https://raw.githubusercontent.com/kpokp/ISSS608_blog/main/_posts/2021-06-10-individual-assignment/images/MC2-tourist.jpg",
    opacity = 0.7,
    layer = "below",
    xref = "x",
    yref = "y",
    sizing="stretch",
    x= 24.8244,
    y= 36.0952,
    sizex= 0.0852,
    sizey= 0.05
  )
))
```

We notice that the highest frequency matches need not coincide with the POI placement on the map. As such, we will visually pick out the lat/long of each POI by checking the points of each POI on the interactive map above.

Most likely geohashes identified per location:
- Abila Airport: sw3thfv
- Abila Scrapyard: sw3tjrh
- Abila Zacharo: sw3tjsm
- Ahaggo Museum: sw3tnpd
- Albert's Fine Clothing: sw3tjxs
- Bean There Done That: sw3tm2r
- Brew've Been Served: sw3tnek 
- Carlyle Chemical Inc.: sw3tnhm
- Chostus Hotel: sw3tnw2
- Coffee Cameleon: sw3tn7s
- Coffee Shack: sw3tjxs
- Desafio Golf Course: sw3tm9z
- Frank's Fuel: sw3tjq8
- Frydos Autosupply n' More: sw3tnsx (uncertain - multiple points)
- GAStech: sw3tn4k
- Gelatogalore: sw3tjsm
- General Grocer: sw3tjse
- Guy's Gyros: sw3tnet (uncertain - multiple points)
- Hallowed Grounds: sw3tnm1
- Hippokampos: sw3tjxs
- Jack's Magic Beans: sw3tnjb
- Kalami Kafenion: sw3tjt8
- Katerina's Cafe: sw3tnev (uncertain - multiple points)
- Kronos Mart: sw3tjmx
- Kronos Pipe and Irrigation: sw3tjj6
- Maximum Iron and Steel: sw3tjm2
- Nationwide Refinery: sw3tnk1 
- Octavio's Office Supplies: sw3tjsm
- Ouzeri Elian: sw3tjgn
- Roberts and Sons: sw3tjt0
- Shoppers' Delight: sw3tjgh
- Stewart and Sons Fabrication: sw3tng3
- U-Pump: sw3tjvy

```{r include = TRUE, warning = FALSE}
# Create a config table of the POI with its most likely geohash
POI_geohash <- tibble(location = c("Abila Airport","Abila Scrapyard","Abila Zacharo","Ahaggo Museum","Albert's Fine Clothing",
                                   "Bean There Done That","Brew've Been Served","Carlyle Chemical Inc.","Chostus Hotel","Coffee Cameleon",
                                   "Coffee Shack", "Desafio Golf Course","Frank's Fuel","Frydos Autosupply n' More","GAStech",
                                   "Gelatogalore","General Grocer","Guy's Gyros","Hallowed Grounds","Hippokampos",
                                   "Jack's Magic Beans","Kalami Kafenion","Katerina's Cafe","Kronos Mart","Kronos Pipe and Irrigation",
                                   "Maximum Iron and Steel","Nationwide Refinery","Octavio's Office Supplies","Ouzeri Elian","Roberts and Sons",
                                   "Shoppers' Delight","Stewart and Sons Fabrication","U-Pump"),
                      geohash = c("sw3thfv","sw3tjrh","sw3tjsm","sw3tnpd","sw3tjxs",
                                  "sw3tm2r","sw3tnek","sw3tnhm","sw3tnw2","sw3tn7s",
                                  "sw3tjxs","sw3tm9z","sw3tjq8","sw3tnsx","sw3tn4k",
                                  "sw3tjsm","sw3tjse","sw3tnet","sw3tnm1","sw3tjxs",
                                  "sw3tnjb","sw3tjt8","sw3tnev","sw3tjmx","sw3tjj6",
                                  "sw3tjm2","sw3tnk1","sw3tjsm","sw3tjgn","sw3tjt0",
                                  "sw3tjgh","sw3tng3","sw3tjvy")) %>% 
                view()

# Fuzzy match of events and transactions by time windows
events_trans <- events %>% 
                fuzzy_left_join(trans_time, 
                by = c("event_start_time" = "timestamp", "event_stop_time" = "timestamp"),
                match_fun = list(`<`,`>`)) %>%
                view()  

```




### Import MC2-tourist.tif created using QGIS
```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
ap <- raster("data/Geospatial/MC2-tourist.tif")
ap
```
### Plotting raster layer using tmap to merge rgb bands
```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
tm_shape(ap) +
tm_rgb(ap, r=1,g=2,b=3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255)
```

### Use sf to import Vector GIS data files in ESRI shapefile format
```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
abila_st <- st_read(dsn = "data/Geospatial",
                    layer = "Abila")
```

### Converting aspatial data into simple feature data frame using st_as_sf
```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
gps_sf <- st_as_sf(gps,
                   coords = c("long","lat"),
                            # EPSG 4326 which stands for wgs84 geo. coord sys
                            crs = 4326)
gps_sf
```

### Creating movement path from GPS points
```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
gps_path <- gps_sf %>%
            group_by(id) %>%
            # Due to peculiar nature of group by, we need to do an action such as summarize
            summarize(m = mean(Timestamp),
                      do_union = FALSE) %>%
            st_cast("LINESTRING") %>%
            ungroup()
            
gps_path
# Have to slice the paths by days, or time period to derive meaningful paths
```

### Plotting the gps paths
```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
gps_path_selected <- gps_path %>% 
                     filter (id==1)

tmap_mode("view")

tm_shape(ap) +
  tm_rgb(ap, r=1,g=2,b=3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
  tm_shape(gps_path_selected) +
  tm_lines()

```

## Insights and Conlusions

### Question 1 
Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies? Please limit your answer to 8 images and 300 words. 

::: l-body
|No| Commentary          | Visual                                       |
|--|---------------------|----------------------------------------------|
|1| text| ![](./images/Q1_1.png){#id .class width=100%}|
|2| text| ![](./images/Q1_2.png){#id .class width=100%}|
|3| text| ![](./images/Q1_3.png){#id .class width=100%}|
|4| text| ![](./images/Q1_4.png){#id .class width=100%}|
|5| text| ![](./images/Q1_5.png){#id .class width=100%}|
|6| text| ![](./images/Q1_6.png){#id .class width=100%}|
|7| text| ![](./images/Q1_7.png){#id .class width=100%}|
|8| text| ![](./images/Q1_8.png){#id .class width=100%}|
:::

### Question 2
Add the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find? Please limit your answer to 8 images and 500 words.

::: l-body
|No| Commentary          | Visual                                       |
|--|---------------------|----------------------------------------------|
|1| text| ![](./images/Q2_1.png){#id .class width=100%}|
|2| text| ![](./images/Q2_2.png){#id .class width=100%}|
|3| text| ![](./images/Q2_3.png){#id .class width=100%}|
|4| text| ![](./images/Q2_4.png){#id .class width=100%}|
|5| text| ![](./images/Q2_5.png){#id .class width=100%}|
|6| text| ![](./images/Q2_6.png){#id .class width=100%}|
|7| text| ![](./images/Q2_7.png){#id .class width=100%}|
|8| text| ![](./images/Q2_8.png){#id .class width=100%}|
:::

### Question 3
Can you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data? Please limit your answer to 8 images and 500 words.

::: l-body
|No| Commentary          | Visual                                       |
|--|---------------------|----------------------------------------------|
|1| text| ![](./images/Q3_1.png){#id .class width=100%}|
|2| text| ![](./images/Q3_2.png){#id .class width=100%}|
|3| text| ![](./images/Q3_3.png){#id .class width=100%}|
|4| text| ![](./images/Q3_4.png){#id .class width=100%}|
|5| text| ![](./images/Q3_5.png){#id .class width=100%}|
|6| text| ![](./images/Q3_6.png){#id .class width=100%}|
|7| text| ![](./images/Q3_7.png){#id .class width=100%}|
|8| text| ![](./images/Q3_8.png){#id .class width=100%}|
:::

### Question 4
Given the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships. Please limit your response to 8 images and 500 words.

::: l-body
|No| Commentary          | Visual                                       |
|--|---------------------|----------------------------------------------|
|1| text| ![](./images/Q4_1.png){#id .class width=100%}|
|2| text| ![](./images/Q4_2.png){#id .class width=100%}|
|3| text| ![](./images/Q4_3.png){#id .class width=100%}|
|4| text| ![](./images/Q4_4.png){#id .class width=100%}|
|5| text| ![](./images/Q4_5.png){#id .class width=100%}|
|6| text| ![](./images/Q4_6.png){#id .class width=100%}|
|7| text| ![](./images/Q4_7.png){#id .class width=100%}|
|8| text| ![](./images/Q4_8.png){#id .class width=100%}|
:::

### Question 5
Do you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why. Please limit your response to 10 images and 500 words.

::: l-body
|No| Commentary          | Visual                                       |
|--|---------------------|----------------------------------------------|
|1| text| ![](./images/Q5_1.png){#id .class width=100%}|
|2| text| ![](./images/Q5_2.png){#id .class width=100%}|
|3| text| ![](./images/Q5_3.png){#id .class width=100%}|
|4| text| ![](./images/Q5_4.png){#id .class width=100%}|
|5| text| ![](./images/Q5_5.png){#id .class width=100%}|
|6| text| ![](./images/Q5_6.png){#id .class width=100%}|
|7| text| ![](./images/Q5_7.png){#id .class width=100%}|
|8| text| ![](./images/Q5_8.png){#id .class width=100%}|
|9| text| ![](./images/Q5_9.png){#id .class width=100%}|
|10| text| ![](./images/Q5_10.png){#id .class width=100%}|
:::


